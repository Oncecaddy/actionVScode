{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8251a051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:/Users/batuh/Downloads/Compressed/Dataset_4\"\n",
    "actions = os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 20\n",
    "\n",
    "frame_width = 64\n",
    "frame_height = 64\n",
    "\n",
    "seed_constant = 86\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2606871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_video_names(dataset_path):\n",
    "\n",
    "  actions = os.listdir(dataset_path)\n",
    "  video_paths = []\n",
    "  video_labels = []\n",
    "\n",
    "  for single_action in actions:\n",
    "\n",
    "    videos = os.listdir(dataset_path + \"/\" + single_action)\n",
    "\n",
    "    for single_video in videos:\n",
    "\n",
    "      single_video_path = dataset_path + \"/\" + single_action + \"/\" + single_video\n",
    "\n",
    "      video_paths.append(single_video_path)\n",
    "      video_labels.append(single_action)\n",
    "\n",
    "  print(f\"There is {len(actions)} action in the dataset.\")\n",
    "  print(f\"There is {len(video_paths)} video in the dataset\\n\")\n",
    "\n",
    "  return np.array(video_paths), np.array(video_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_preprocess(frame):\n",
    "\n",
    "  resized_frame = cv2.resize(frame, (frame_height, frame_width))\n",
    "\n",
    "  normalized_frame = resized_frame / 255\n",
    "\n",
    "  return normalized_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video (video_path):\n",
    "\n",
    "  frames_list = []\n",
    "\n",
    "  cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "  ok, frame = cap.read()\n",
    "\n",
    "  video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "  skip_ratio = max(int(video_frame_count/frame_count), 1)\n",
    "\n",
    "  for i in range(frame_count):\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i * skip_ratio)\n",
    "\n",
    "    oke, frame = cap.read()\n",
    "\n",
    "    if not oke:\n",
    "      break\n",
    "\n",
    "    frame = video_preprocess(frame)\n",
    "\n",
    "    frames_list.append(frame)\n",
    "\n",
    "  if len(frames_list) != frame_count:\n",
    "    print(f\"There is not enough number of frames in this video {video_path}\")\n",
    "\n",
    "  cap.release()\n",
    "\n",
    "  return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_s = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "videos, labels = take_video_names(dataset_path)\n",
    "\n",
    "for one_video in videos:\n",
    "\n",
    "  count = count + 1\n",
    "\n",
    "  feature_s.append(load_video(one_video))\n",
    "\n",
    "  print (f\"{count/len(videos)*100} percent complete \")\n",
    "\n",
    "feature_s = np.array(feature_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07729fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feature_s))\n",
    "print(type(feature_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f731ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(feature_s, \n",
    "                                                                            one_hot_encoded_labels, \n",
    "                                                                            test_size = 0.25, \n",
    "                                                                            shuffle = True, \n",
    "                                                                            random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcde04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del feature_s\n",
    "del labels\n",
    "del count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LRCN_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu'),\n",
    "                              input_shape = (frame_count, frame_height, frame_width, 3)))\n",
    "    \n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4)))) \n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                                      \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "                                      \n",
    "    model.add(LSTM(32))\n",
    "                                      \n",
    "    model.add(Dense(len(actions), activation = 'softmax'))\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ec4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRCN_model = create_LRCN_model()\n",
    "\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 60, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "LRCN_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "LRCN_model_training_history = LRCN_model.fit(x = features_train, y = labels_train, epochs = 70, batch_size = 4 ,\n",
    "                                             shuffle = True, validation_split = 0.2, \n",
    "                                             callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f49ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LRCN_model_training_history.history.keys())\n",
    "plt.plot(LRCN_model_training_history.history['accuracy'])\n",
    "plt.plot(LRCN_model_training_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ae022",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LRCN_model_training_history.history['loss'])\n",
    "plt.plot(LRCN_model_training_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a44005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_history = LRCN_model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(labels_train, axis=1)\n",
    "y_pred = LRCN_model.predict_classes(features_train)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_camera():\n",
    "\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    \n",
    "    cam_frame_list = deque(maxlen = frame_count)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ok, cam_frame = cam.read()\n",
    "    \n",
    "        if ok == True:\n",
    "        \n",
    "            normalized_cam_frame = video_preprocess(cam_frame)\n",
    "\n",
    "            cam_frame_list.append(normalized_cam_frame)\n",
    "\n",
    "        if len(cam_frame_list) == 20:\n",
    "\n",
    "            predicted_labels_probabilities = LRCN_model.predict(np.expand_dims(cam_frame_list, axis = 0))[0]\n",
    "            \n",
    "            for i in range(len(actions)):\n",
    "                \n",
    "                if predicted_labels_probabilities[i] > 0.95 and predicted_labels_probabilities[i] < 1.0:\n",
    "                    \n",
    "                    predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "\n",
    "                    predicted_class_name = actions[predicted_label]\n",
    "\n",
    "                    cv2.putText(cam_frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "        cv2.imshow(\"Frame\", cam_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84667333",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    predict_on_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0da0c-43b2-488e-89a0-e2e5b6bc5b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e5b9b3163378c0142876ad9516620f7ba55e4d221a56e22640f02134f2e2f31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
